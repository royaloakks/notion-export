# Filterworld

Author: Kyle Chayka
Publication Date: 2024
Year Read: 2024

In place of the human gatekeepers and curators of culture, the editors and DJs, we now have a set of algorithmic gatekeepers. While this shift has lowered many cultural barriers to entry, since anyone can make their work public online, it has also resulted in a kind of tyranny of real-time data. Attention becomes the only metric by which culture is judged, and what gets attention is dictated by equations developed by Silicon Valley engineers. The outcome of such algorithmic gatekeeping is the pervasive flattening that has been happening across culture. By flatness I mean homogenization but also a reduction into simplicity; the least ambiguous, least disruptive, and perhaps least meaningful pieces of culture are promoted the most.
Flatness is the lowest common denominator, an averageness that has never been the marker of humanity's proudest cultural creations. P9

Algorithms are digital machines that turn a series of inputs into a particular output, like a conveyor belt in a factory. What makes one algorithm different from another is less their structure than the ingredients they are built from. All recommendation algorithms work by gathering a set of raw data. The overall term for that dataset is signal, the collected inputs that are fed into the machine. The signal data might include a user's past purchases on Amazon or how many other users favorited a particular song on Spotify. The data is quantitative rather than qualitative, since it must be able to be processed by the machine. So even if the data is about something as subjective as music preferences, it is translated into numbers: x number of users rated y band an average of z, or x number of users listened to y band z times. The primary signal fed into many social media recommendations is engagement, which describes how users are interacting with a piece of content. That might come in the form of likes, retweets, or plays— any kind of button found next to a post. High engagement means the number of likes, views, or shares is higher than the average of other posts. P19

An executive at the music cataloging and recommendation service Pandora once described the company's system to me as an
"orchestra" of algorithms, complete with a "conductor" algorithm.
Each algorithm used different strategies to come up with a recom-mendation, and then the conductor algorithm dictated which suggestions were used at a given moment. (The only output was the next song to play in a playlist.) Different moments called for different algorithmic recommendation techniques. P20

"The volume of things is considerably more than any person can possibly filter through in order to find the ones that he or she will like." Automated filters would be necessary, they concluded: "We need technology to help us wade through all the information to find the items we really want and need, and to rid us of the things we do not want to be bothered with." (Of course, this is still a huge problem online.) Shardanand and Maes argued that content-based filtering had significant drawbacks. It requires the material to be translated into data that the machine can understand, such as text; it lacks serendipity because it can filter only by the terms that the user inputs; and it does not measure inherent quality. It is unable to "distinguish a well written (and] a badly written article if the two articles use the same terms." The inability to evaluate quality brings to mind artificial intelligence: New tools like ChatGPT seem to be able to understand and generate meaningful language, but really, they only repeat patterns inherent in the preexisting data they are trained on. Quality is subjective; data alone, in the absence of human judgment, can go only so far in gauging it. P23

Facebook's Like button, with its signature thumbs-up, was introduced in 2009, providing one form of data on how interested a user might be in a particular piece of content. User engagement, measured by likes, comments, and one account's previous interactions with another, factored into the order of the feed. That algorithmic system was called EdgeRank, and Facebook identified its principal variables as affinity score, edge weight, and time decay. "Edge" referred to any action people carry out on Facebook, which is then sent to the News Feed as an update to be listed. Affinity score represented how connected a user was to the poster and the strength of the connection (eg., consistently commenting on friend's posts). A comment counted more than a like, and recent interactions counted more than older ones. Edge weight evaluated different categories of interactions: an update of a friend posting a new photo might be given more weight by the algorithm than posting a link to a news article or joining a new group. Time decay was the age of the action; recent actions were more likely to be at the top of the News Feed than older ones, if the other factors were equal. The EdgeRank scores were not permanently assigned once, like the outcome of a basketball game in a tournament, but changed instant to instant.
And those three categories aren't simply single, neutral data points; they are collections of data packaged and interpreted in specific ways by Facebook. P30

The algorithmic feed itself is not consistent or on a linear path toward some ultimate perfection. It changes with a company's priorities. P30

The advent of Filterworld has seen a breakdown in monoculture. It has some advantages— more than ever before, we can all consume a wider possible range of media-but it also has negative consequences. Culture is meant to be communal and requires a certain degree of consistency across audiences; without communality, it loses some of its essential impact. P33

a fundamental rule of Filterworld:
Under algorithmic feeds, the popular becomes more popular, and the obscure becomes even less visible. Success or failure is acceler-ated. "A traditional Instagram post, the life of it is dictated by the first three to five minutes. P37

In 2018, Shagun Jhaver, at the time a PhD candidate at the Georgia Institute of Technology, worked with two Airbnb employees to conduct a sociological study of the company's users. They analyzed how the platform's hosts— who rented out their homes on the service for income interacted with and felt about Airbnb's algorithmic recommendation, search, and ratings systems, which helped renters find and book their listings. Jhaver and the other researchers coined the term algorithmic anxiety for the hosts' "uncertainty about how Airbnb algorithms work and a perceived lack of control," the team wrote in their findings. Hosts worried that the search algorithm was unfairly ignoring them or prioritizing other properties. Jhaver noticed that the anxiety was ascribed more to the technology than the quality of the actual homes the hosts were renting out: "It was particularly to do with the algorithm itself rather than improving their listing and property in other ways," he told me. P38

"At the end of the day, even the people who create the algorithms cannot tell you which factor was responsible for which decision; the complexity of the algorithm is so high that disentangling different factors is just not possible.” P39

Algorithmic anxiety happens because there is a dramatically asymmetrical relationship between user and algorithm. For the individual user, trying to predict or dictate the outcome of the algorithm is like trying to control the tide. To continue the metaphor, all users can do is surf the wave that's already formed. There is little incentive for companies to assuage this anxiety because a user's confusion can be beneficial to business. When a company's product is ineffective or a user encounters difficulty, it can be blamed on the opaque entity of "the algorithm," which is perceived as external to both the users and the company itself, since they are likened to opaque "black boxes." Exploitation is disguised as an accidental glitch instead of an intentional corporate policy. In reality, a company like Facebook is wholly in control of their algorithmic systems, able to change them at will—or turn them off.
Algorithmic anxiety places the burden of action on the individ-ual, not the business— the user must change their behavior or risk disappearing. Users sometimes complain of being "shadowbanned" when their posts or content on a platform suddenly lack the same level of engagement as before. Users often fear that their account specifically has been blocked without warning or recourse by some decision-maker; but the algorithmic priorities may simply have silently changed, and traffic is no longer flowing in their direction. The effect goes back to the Mechanical Turk; we can't always tell the difference between technology working and the illusion of technology working, but the perception may be just as impactful, in the end, as the reality. P40/41

The consequences of such anxiety include "algorithmic determinism, fatalism, cyni-cism, and nihilism," de Vries wrote. It builds to a sense that, since we users cannot control the technology, we may as well succumb to the limits of algorithmic culture and view it as inevitable. Many users have already entered such a state of despair, both dissatisfied and unable to imagine an alternative. P41

The brand a customer picks says as much about them as it does about the brand it's a reciprocal relationship between creator and customer, with the customer believing (or hoping) that the brand's ethos is representative of their own identity.
A shopper doesn't go to Nike just because they want good running shoes; Nike casts an aura of youth and energy over everything it pro-duces, whether sneakers or brightly screen-printed T-shirts. Zara makes dresses, among many other clothing items, and through them projects a sense of cutting-edge style without the cost of traditional luxury brands. To buy a Zara dress is to participate in its image of efficient glamour—a nightly party. Every piece in the store refers to that sensibility. In other words, each store serves a particular sensibility, and consumers select from them based on their individual tastes. P43

A joke written on Twitter by a Google engineer named Chet Haase in 2017 pinpoints the problem: "A machine learning algorithm walks into a bar. The bartender asks, 'What'll you have?' The algorithm says, 'What's everyone else having?'" The punch line is that in algorithmic culture, the right choice is always what the majority of other people have already chosen. But even if everyone else was, maybe you're just not in the mood for a whiskey sour. P46

Taste is a word for how we measure culture and judge our relationship to it. If something suits our taste, we feel close to it and identify with it, as well as form relationships with other people based on it, the way customers commune over clothing labels (either loving or hating a particular brand). Intentionally bad taste might be just as compelling as good taste, as the author Rax King described in her book Tacky: "Tackiness is joyfulness." But in its origins, taste is a much deeper philosophical concept. It borders on morality, representing an innate sense of what is good in the world. P48

"In order to have taste, it is not enough to see and to know what is beautiful in a given work. One must feel beauty and be moved by it. It is not even enough to feel, to be moved in a vague way: it is essential to discern the different shades of feeling." Taste goes beyond superficial observation, beyond identifying something as "cool." Taste requires experiencing the creation in its entirety and evaluating one's own authentic emotional response to it, parsing its effect. (Taste is not passive; it requires effort.) P48

When recommendation algorithms are based only on data about what you and other platform users already like, then these algorithms are less capable of providing the kind of surprise that might not be immediately pleasurable, that Montesquieu described. The feed structure also discourages users from spending too much time with any one piece of content. If you find something boring, perhaps too subtle, you just keep scrolling, and there's no time for a greater sense of admiration to develop-one is increasingly encouraged to lean into impatience and superficiality in all things. P51

Building your own sense of taste, that set of subconscious principles by which you identify what you like, is an uphill battle compared to passively consuming whatever content feeds deliver to you. But the situation can't solely be blamed on the presence of algorithms. Today we have more cultural options available to us than ever and they are accessible on demand. We are free to choose anything. Yet the choice we often make is to not have a choice, to have our purview shaped by automated feeds, which may be based on the aggregate actions of humans but are not human in themselves. P51

I find myself mortified when I pick out a previously unexplored bar or restaurant for a group of friends, a choice I think will be a crowd-pleaser, and it turns out to have entirely the wrong vibe. (One such bar in D.C. turned out to have too many taxidermy animal heads on the walls for com-fort.) In that situation, an automated recommendation from Yelp or Google Maps may have suited me better: the proof of demo-cratic, average approval takes the pressure off making a choice that may prove too quirky. Yet at the same time, I wouldn't want those lowest-common-denominator rules to determine which books I read or television shows I watch. Culture isn't a toaster that you can rate out of five stars—-though the website Goodreads, now owned by Amazon, tries to apply those ratings to books. There are plenty of experiences I love— a plotless novel like Rachel Cusk's Outline, for example-that others would doubtless give a bad grade. But those are the rules that Filterworld enforces for everything. P52

There are two forces forming our tastes. As I described previ-ously, the first is our independent pursuit of what we individually enjoy, while the second is our awareness of what it appears that most other people like, the dominant mainstream. The two may move in opposite directions, but it's often easier to follow the latter, particularly when the Internet makes what other people are consuming so immediately public. (If you didn't post about it, did you really watch a TV show?) Algorithmic feeds further reinforce the presence of that mainstream, against which our personal choices are evaluated. Taste is inescapable; it involves "the most everyday choices of everyday life, e.g, in cooking, clothing, or decoration," the French sociologist Pierre Bourdieu wrote in his 1984 book Distinc-tion: A Social Critique of the Judgement of Taste. These choices can be symbolic of a range of things beyond just our aesthetic preferences, such as economic class, political ideology, and social identity. "Taste classifies, and it classifies the classifier," Bourdieu wrote. No wonder that we worry about what to like, and sometimes find it simpler to export that responsibility to machines. P53

Should the human fashion editor tell you what to like or should it be the algorithmic machine, in the form of the Amazon bookstore, Spotify feed, or Netflix home page? That is the central dilemma of culture in Filterworld. The former option is mercurial and driven by elite gatekeepers, a powerful group built up over a century of modern cultural industries, riddled with their own blind spots and biases including those of gender and race. (That group includes not just the mostly white fashion magazine editors of New York City but also Hollywood producers, record-label executives, and museum curators.) Yet the human flaws may become even more dramatic in an algorithmic ecosystem when the actions of mass audiences dictate what can easily be seen. Racism, sexism, and other forms of bias are a de facto part of that equation.
Online, users are often insulated from views and cultures that clash with their own. The overall digital environment is dictated by tech companies with ruthlessly capitalist, expansionary motives, which do not provide the most fertile ground for culture. While the magazine fashion editor may periodically use their ability to pick out and promote a previously unheard voice, the algorithmic feed never will; it can only iterate on established engagement. We users have less chance of encountering a shockingly new thing and deciding for ourselves if we like it. Fashion, to take one example, is often strongest as an art form when it doesn't follow the rules and chase averages. Part of its appeal lies in breaking with the social code: wearing something unexpected or strange, even at times challenging your own taste. It's something that no automated recommendation alone can approximate. Algorithmic feeds are a double-edged sword:
A marginalized fashion designer might find a way to game the Instagram algorithm and spark their own popularity without waiting to be noticed by a white editor who might be biased against them.
But they are then conforming to the tenets of a tech company even more powerful and more blinkered than the editor. P55/56

The only thing that had changed to possibly cause the "Strange" phenomenon was that in 2017, Spotify had made its autoplay option the default. So anytime the music that the user had chosen stopped-whether a track, album, or playlist-another algorithmically recommended song would instantly play.
"On the day that they switched the preset, it was the beginning of this separation of one song from the rest of our catalog," Krukowski said: "Strange" was being recommended by that system more often than any of Galaxie 500's other songs. Krukowski posted his observations in a newsletter, which attracted the attention of Glenn McDonald, who at the time worked as Spotify's "data alche-mist." McDonald did an internal investigation and concluded that "Strange" had hit the algorithmic jackpot not because of Galaxie 500's unique musical style, but because the song was more similar to songs by other bands than Galaxie 500's other tracks. In many cases, if "Strange" played, the listener was unlikely to hit the Skip or Stop button, and so the recommender system registered it as an effective selection and offered it to ever more listeners. P60/61

This is how algorithmic normalization happens. Normal is a word for the unobtrusive and average, whatever won't provoke negative reactions. Whichever content fits in that zone of averageness sees accelerated promotion and growth, like "Strange" did, while the rest falls by the wayside. As fewer people see the content that doesn't get promoted, there is less awareness of it and less incentive for creators to produce it—in part because it wouldn't be financially sustainable. (The rule of culture in Filterworld is: Go viral or die.) P61

As Pajkovic wrote, "Feedback loops reinforce a user's preexisting preferences, diminishing their exposure to a diverse range of cultural offerings and denying art, aesthetics and culture of its confrontational societal role." That lack of confrontation is concern-ing. It's not that great art needs to be inherently offensive; rather, when everything conforms to established expectations, we miss out on culture that is truly progressive and uncomfortable, that might subvert categories rather than fit neatly into them. P70

Algorithmic culture congregates in the center, because the decision to consume a piece of culture is rarely motivated by hate or conflict. Jingjing Zhang, a professor at Indiana University who studies recommendation algo-rithms, found evidence for the theory of homogenization when she collaborated on an experiment about personalized music recom-mendations, presented at the 2012 Dublin Conference on Recommender Systems.
Students were presented with songs that they were told had been recommended to them based on their personal taste, as indicated by a star rating but the ratings were actually artificial and arbi-trary. Students were then asked how much they would pay for a given song; the higher the star rating, the more they were willing to pay. Each added star resulted in a 10 to 15 percent increase in willingness to pay for the song. The experiment showed how the perception of recommendation could skew the perceived value of a given piece of culture, making it seem more likable or significant.
The flaw intensifies due to the self-reinforcing loop of algorithmic recommendations. Over time, the system will "provide less diverse recommendations," as Zhang told the podcast Planet Money. Even-tually, she said, it will "provide similar items to everybody, like, regardless of personal taste." Hence the homogenization we are experiencing today. P72

Benjamin's library was a personal monument, the same kind that we all construct of things we like or identify with, building our sense of taste. Its importance lay in its permanence collections are made up of things that we own, that don't go away unless we decide they should. "Ownership is the most intimate relationship that one can have to objects,
" Benjamin wrote. "Not that they have come alive in
him; it is he who lives in them." In other words, we often discover, and even rediscover, ourselves in what we keep around us. But that codependence or co-evolution of collection and person wouldn't happen if the order of Benjamin's shelves and the catalog of his books kept changing every few months. That's what Spotify's interface updates and algorithmic changes felt like to me: a total disruption of the pieces of art and culture that shaped me. P75

In Filterworld, culture is becoming more ambient. Like Sleepify, it's designed to be ignored, or, like the Marvel movie franchise, no single moment or fragment of it is particularly significant because there is always more to be consumed. When we embrace ambience, we lose the meaning of the finite and the discrete. P85

In the place of physical hotels and airports, we have Twitter, Facebook, Instagram, and TikTok as spaces of congregation that erase differences. Moving past Koolhaas's "Generic City," there is now also the generic global consumer, whose preferences and desires are molded more by the platforms they use than where they live. In some cases, we conduct our lives more in the space of flows than the space of places. P104

Simply existing as a coffee shop isn't enough; the business has to cultivate a parallel existence on the Internet, which is a separate skill set entirely. "It almost feels like, you must have a social media acu-men, you must be savvy in this area that is adjacent to your business, but not directly embedded in your business, in order to be successful and visible," Walsh continued. That means achieving metrics like plenty of tagged photos on Instagram and positive user reviews on the business's listing on Google Maps. The end point of this pressure to have a digital presence was a form of restaurant that only existed online. P110

Ungureanu developed an Instagram account full of cappuccino snapshots and accrued over seven thousand followers but grew frustrated when she felt that the platform was taking away her ability to access her audience through the feed. When her café started selling coffee online, Facebook and Instagram seemed to throttle their reach-unless they bought ads and boosted the social media company's own profits. It felt like algorithmic blackmail: pay our toll or we won't promote you. The tools that had served the cafe to grow and access new customers were suddenly being turned against it.
Facebook and Instagram "don't let you take advantage of the community you've already built. From a certain moment onward, things are unfair," Ungureanu said. P111

Pursuing Instagrammability is a trap: the fast growth that comes with adopting a recognizable template, whether for a physical space or purely digital content, gives way to the daily grind of keeping up posts and figuring out the latest twists of the algorithm-which hashtags, memes, or formats need to be followed. Digital platforms take away agency from the business owners, pressuring them to follow in lockstep rather than pursue their own creative whims. There's a risk as well in hewing too closely to trends. Cliché is not desirable.
If a trope is too stale, the algorithmic audiences won't engage with it, either. That's why the perfect generic coffee shop design keeps changing slightly, adding more potted plants or taking a few away. In the algorithmic feed, timing is everything. P112

The other strategy is to remain consistent, not worrying about trends or engagement and simply sticking to what you know best— staying authentic to a personal ethos or brand identity in the deepest sense. P112

attention-tend to speak louder than the piece of culture itself. Not only do they act as a measure of success, but they create success, because they dictate what is recommended to and seen by audiences in the first place. P132

Suddenly, users could tell how every little piece of content compared to every other one. The numbers could not be escaped, popping up next to everything you read or watched. Even if the count of likes, shares, retweets, or faves was an artificial measure of value imposed by the platform itself, they still became the fastest and easiest way to judge what popped up in the infinite feeds of content. More was always better: if a YouTube video had a lot of views, perhaps it might be insightful or at least funny. Virality equaled quality-other people liked this, so you will, too. For cre-ators, whether writers or aspiring Instagram influencers, metrics were the goal, the incentive, and the internal compass evaluating what worked and what didn't. Particularly in journalism, the higher the numbers, the more important something seemed to be. It was a truism: more likes meant more people had seen something. Each like was a vote in the seemingly meritocratic Internet, where anyone could upload content but certainly not everyone could inspire audiences to pay attention. P133

This is not a new pressure; it's basic human psychology to want to be liked, and we ultimately like what is most similar to us, the same way that mirroring another person's body language in conversation can make you appear more convincing or empathetic. Likability binds society together with the shared incentive to not offend or alienate. Yet interpersonal likability has not been a common metric of culture, particularly the kind of innovative art we have prized over the past century or two. Art itself-not to mention artists as people— tends not to be bound by the quest for likability, and yet likes are what the current tyranny of quantification prioritizes most. In Filterworld, what is likable succeeds and what is not likable is doomed to fail, particularly in any arena of culture where audiences are requisite for survival. And because our American cultural landscape is almost entirely subservient to capitalism, that means more or less all of it. P138/139

"These streaming services have been making something they call 'movies' They ain't movies. They are some weird algorithmic processes that has created things that last 100 minutes or so." "Much of culture now has the hollow, vacant feeling of having been made by algorithm," wrote the critic Dean Kissick, one of the more incisive commentators on contemporary culture, in 2021. "Algorithmic" has become a byword for anything that feels too slick, too reductive, or too optimized for attracting attention: a combination of high production values with little concern for fundamental content. P140

 

All culture is now content, and the platforms we use to access it encourage us to treat it as interchangeable. P144

Everything exists within the algorithmic context of passive, frictionless consumption. No matter that a book or other piece of content seems to exist outside of the algorithmic ecosys-tem; it is still informed by the dominant aesthetics and trends that algorithmic feeds have given rise to. The end point of algorithmic culture is a constant flow of similar-yet-different content, varied enough so as not to be utterly boring but never disruptive enough to be alienating. Reaching toward an ambitious artistic ideal may have faded in favor of refinement toward the goal of likes and engagement above all. P148/149

The cultural ecosystem of Filterworld puts the cart before the horse: The needs of promotion and marketing supersede the object that is meant to be promoted. Not only does culture have to be designed to generate external content to serve as marketing on digital platforms; the platforms also profit from the increased engagement driven by new content. It can be seen as either a symbiotic relationship or a vicious cycle, reinforcing the need to cater to the aesthetic requirements of the platform. Optimizing for this equation-second-guessing a creative process in advance is much easier than finding an alternative to it. At this point, many pieces of contemporary culture have come to resemble or glorify the social platforms themselves—all the better to be distributed through them. P151

After all, if the bulk of culture now takes place on social media, what more powerful role could there be than controlling the flow of attention and being able to direct an audience in particular ways?
(Influencers are the cowboys of algorithms.)
The superficiality of the word itself is indicative: "influence" is never the end point, only a means of communicating a particular message. An influencer is easiest to define by how they make money.
Like a media company producing magazines or podcasts, they sell advertising shown to the audiences that they have gathered. But the content that draws the audiences in in the first place is most often the influencer's personal life, their aesthetically appealing surroundings (as well as aesthetically appealing selves) and entertaining activities. The material of their lives— in varying degrees of organic and staged-is copiously documented on social media platforms like Instagram, where they also publish sponsored posts for brands.
Another difference is that unlike a free newspaper distributed on the street or a radio station sending out a signal, influencers don't own the infrastructure of their medium. They piggyback on the digital platforms' ability to distribute content, both through widely installed smartphone apps and through in-app feeds. P154

2016, when its feed changed from chronological to algorithmic.
"For me, personally, in the way that I grew through social media, the change of the platform to give power to the algorithm was worst possible thing," he told me. Originally, he could post several times a day and know that his posts would reach his followers in real time, in a chronological order that made sense for his storytelling. Now he can't tell when or in what order his images will show up. It's frustrating on the consumption side as well as creation: "No one is really given that choice to make that decision for themselves, to curate what they're seeing in a way that feels great to them. It's all being dictated by the algorithm." P160

This need to corral an audience in advance by succeeding on social media can be explained by the useful phrase "content capital."
Established by the scholar Kate Eichhorn in her 2022 monograph Content, it describes the Internet-era state in which "one's ability to engage in work as an artist or a writer is increasingly contingent on one's content capital; that is, on one's ability to produce content not about one's work but about one's status as an artist, writer, or per-former." In other words, the emphasis is not on the thing itself bur the aura that surrounds it, the ancillary material that one produces because of living the lifestyle of a creator. That ancillary content might be Instagram selfies, photos of a painting studio, evidence of travel, tossed-off observations on Twitter, or a monologue on Tik Tok It all builds an audience for the person, who remains a separate entity from the things that they make. If Roland Barthes's 1967 essay predicted "the death of the author," the author's personal brand is now all that matters; it's the work itself that is dead. P164

Eichhorn responds to the sociologist Pierre Bourdieu's 1970s concept of "cultural capital": the fluency in forms of high culture that could bestow social status and help members of elite classes to identify one another. Cultural capital is knowing that cashmere is a more aspirational fabric than cotton or that a Jackson Pollock painting is much more than a mess of drips that a child could rep-licate. (Bourdieu points out that, in the West, being open to radical aesthetic experimentation and abstraction are markers of the elite class.) Not only is it an understanding of art; it is an understanding of what art means in a social context, and what different pieces or artists symbolize. Content capital, then, is fluency in digital content: the knowledge of what kinds of content to produce, how the feeds of various platforms work, what they prioritize, and how audiences might react to a given creation. Those who have more content capital gain more followers, and thus more power in the cultural ecosystem of Filterworld. P165

That is not to say that content begets art. In fact, the excess content demanded by algorithmic feeds more often gets in the way of art, because it sucks up an increasingly high percentage of a creator's time. "Cultural producers who, in the past, may have focused on writing books or producing films or making art must now also spend considerable time producing (or paying someone else to produce) content about themselves and their work," Bich-hom wrote. As anyone who has tried to get an undertaking off the groand online-a bake sale, a party, an art installation-knows, ancillary content quickly becomes a distraction. The author (me) is too busy instagramming his artfully cluttered desk, broadcasting his writerly identity, and checking for subsequent likes to actually write his book. P166

The instantaneous wave of likes in response to a post helps the recommendation algorithm evaluate which pieces of content should be promoted, but it also gives the creator an unprecedented realtime measure of what resonates with their audiences, as if every thought was gauged by a Nielsen rating viewable on a smartphone.
Cultural flattening is one consequence. But the same mechanism is also what makes our public political discourse more and more extreme, because conflict and controversy light up the feed and attract likes in a way that subtlety and ambiguity never will. P168

Knowing how and why something has been recommended might help to dispel the air of algorithmic anxiety that surrounds our online experiences, since we could identify which of our actions the recommendations are considering. Still, it leaves users responsible for themselves: Knowing how the algorithm works isn't the same as being able to control it. "Transparency alone cannot create accountable systems," Ananny and Crawford wrote. P197

"We click with our monkey brains, the same ones that cause us to buy a candy bar in the checkout line at the grocery store." Algorithmic feeds accelerate these worst impulses, not just on an individual level but an aggregate one, across all the users of a social network. Titillating material-content that might be violent, pro-vocative, or misleading— can be easier to discover than material that is more boring but also more valuable. P210

While previous generations might have had dance halls or independent radio stations to help them discover new music during their formative teenage years, and young people in the twenty-first century have Til Tok feeds and Spotify playlists, millennials in the late 1990s and early 2000s had online forums and MP3 piracy. These required much more labor to find what you like and consume it than the frictionless avenues of algorithmic feeds. While avoiding that labor may be convenient, it also makes our personal tastes flimsier, less hard-won. P231

Those forums were "communities of con-sumption," a term that academics have used to describe the diverse groups of people that congregate online around a particular shared pursuit, whether swapping product tips or discussing avant-garde literature. One paper described communities of consumption as a form of "mutual learning" — we collectively figure out what it is that we're looking for and how to find it. The likes of Twitter and Facebook with their unstable interfaces and manipulative algorithms, are less conducive to mutual learning. P232/233

A lot of human effort is required to create something original, no matter the intended outcome. As my art-critic friend Orit Gat once told me, partly joking but also serious, you should look at a painting for as long as it took the artist to paint it. Flipping through so much incoherently assembled content in our feeds, we don't have the opportunity to assimilate it, to learn and understand, much less pass on that understanding to others. That encouraged shallowness of consumption contributes to the overall flatness of culture in Filterworld. P234

Filterworld consists of one fundamental, unavoidable reality: never in human history have so many people experienced the same things, the same pieces of content disseminated instantly through the feeds, to our individual screens. Every consequence flows from that fact. P274