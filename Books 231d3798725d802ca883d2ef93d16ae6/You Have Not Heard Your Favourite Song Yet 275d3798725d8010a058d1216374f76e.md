# You Have Not Heard Your Favourite Song Yet

Author: Glenn McDonald
Publication Date: 2024
Year Read: 2025

Streaming is surveillance capitalism. 

At least, it's definitely capitalism. Whether it's 'surveillance' or not depends on whether you think that means something more than operating a system which inherently requires information exchange in order to function. When you hit play on a song, the app running on your phone or computer sends a message to the streaming service's servers. That message identifies the song you're trying to play, because that's the point, and the user-ID of your streaming account, because that's how the service can tell if you're allowed to play that song. When you hit pause or skip or switch to a different song, the app sends another message to the servers. These messages themselves aren't really surveilling you any more than a lightbulb is surveilling the switch that turns it on or off. Lightbulbs, however, don't keep logs of their ons and offs.
Actually, maybe smart bulbs do. A streaming service does. It has to, logistically and legally, because it has to pay royalties. P37

Except, of course, music is human and humans often have gender, and in most places in the world overall music tastes differ by age and gender almost as dramatically as they differ by country and language. It's thus a practical statistical advantage, from the point of view of a streaming service trying to recommend music to brand new listeners who haven't played anything yet, to give them music that other people of their country, age and gender already like. P39

As you listen, you either reinforce or refute these low-grade demographic inferences, and over time you assert your own listening patterns. The amount of data changes steadily, but the shape of it never really does. Spotify never knows your ethnicity, your poli-tics, your occupation, your income, your shopping patterns or your medications. It doesn't know what you tell Siri, or what you look up on WebMD. It doesn't cross-reference your Netflix queue or your YouTube subscriptions. It can't see that you're wearing a band t-shirt. It can't tell that the band t-shirt you're wearing is 35 years old, and it doesn't know that the guy on the left in the hat died yesterday, and it wouldn’t know which song you need to hear in your grief. P40/41

The moments when you step outside of your own assumptions about yourself, and become somebody slightly new, are too rare and too singular to optimize for. It's far easier, and far more reliable, to just feed you more of the already-familiar. P41

And this is the problem, rather than the promise, I think, of the myopically limited kind of surveillance that streaming services subject us to. They don't know our hidden secrets. They don't know how to find them out. Before we start listening, they can only guess that we are exactly like the people they've seen before, but they never learned that much about those people, either.
But they also barely know the unsecrets we try to share. They know what we play, but they can't see whether we're dancing enraptured while the music spins, or two rooms away folding distractingly crinkly laundry. They know which songs we put on playlists, but not what the playlists are for. They know when we play a song ten times, but not whether we're doing it because of the drums or in spite of the banjo. They know what we click on when we search, but not whether we knew what we were looking for. They can't tell whether we scroll past their offerings in disdain or distraction.
They can't distinguish between joy and irony, or whether we were driven away by the miserable song that was playing or torn away from a crescendoing new love by the sound of a cat, somewhere downstairs, throwing up into one of our shoes.
And they're not likely to start learning any of these things, because they don't need to. Your cat is your problem. You're not really being surveilled, but that's not due to teleological humility or ethical judiciousness, it's just that invasive surveillance doesn't address any business problem that isn't at once more easily and more effectively solved by regression to the mean. Automated serendipity is a hard bet, but it's also a bad bet. The lowest common denominator might sound like an aesthetic condemnation, but it's exactly the goal of factoring. Night Ranger's 'You Can Still Rock in America' isn't what I want to hear right now, but it definitely was once, and the nostalgia might be lazy and ineffective, but it's not offensive. I smile, and hum a little of that chorus to myself as I go oft, clicking ambiguously and cheerfully, in search of Sámi yoiks or n dehou fusion or cat-calming music or whatever it is I alone know I want to hear next. P41/42

We know things about each other, our weaknesses and embarrassments and vulnerabilities as much as our powers and accomplishments and concealed contours. Facts accumulate into insights, and past observations lead to future in-tentions. At least, that's what happens in our brains.
That's not what happens inside of a computer. The computer may have a lot of your data, but it doesn't know about you, any more than a refrigerator knows about eggs. Fill a refrigerator entirely full of eggs, and it still doesn't know any more about eggs than when it was empty. P43

Algorithms can get a lot more complicated than that, but they never get any smarter. They do not seek out challenges, they do not think flexibly, they don't persevere to understand, and they don't construct or critique arguments. They basically permanently fail at all the foundational Habits of Mind from my kid's elementary school. They are not minds. They are, at most, symbolic machines.
And more often than not, these 'machines' are just math. 'Just' is a mean-spirited word to use for this, though. Math is very useful.
Symbolic machines can do extremely helpful symbolic work, and songs and fascinations are made of symbols.
Streaming music services are full of algorithms. If the most important thing to know about algorithms is that most of them are just math, the second-most important thing to realize about algorithms is that there is never just one. There is no 'Spotify Algorithm', there are different algorithms for almost every feature. Sometimes a single feature involves multiple algorithms. Almost everything in any online experience involves some kind of algorithm. P44

And although lots of these algorithms are simple, some of them are not only complicated, but complicated in humanly unmanageable ways. This family of complex algorithmic techniques is called machine learning, or ML for short. It has powers and drawbacks that we will discuss later, but it also has a bad name. Machines don't learn any more than they know, so when a human tells you a machine is learning, you can safely infer that nobody is learning.
Sometimes ML works despite this, and sometimes it causes chaos.
So the good news is that the robots are not plotting your downfall.
The robots have no domination plan, and indeed no plans at all, and anyway there are no robots. The bad news is that we can't blame robots when things go wrong. Wrong is a human direction.
You don't need to fear the fact that algorithms exist, or even the way they now surround you. P48

Almost inevitably, though, the biggest playlists tend to encounter variations on the same structural and cultural limitations as radio stations. Influence is garnered by demonstrating power, but to demonstrate power you have to concentrate it. RapCaviar currently has 50 songs, not 40, but it's the same circular premise.
RapCaviar is a big deal because getting on it means you reach tens of millions of listeners, and tens of millions of listeners follow it in order to know the hip hop that matters to those tens of millions of listeners. That only works if the playlist is short enough that everything on it gets played repeatedly. RapCaviar has the clout to break a new rapper, but it gets that clout by being the place where you go to find the hip hop that matters most, which means it mostly has to program music by rappers whose importance is already established. It has to change to stay current, but it can't abandon songs that still hold cultural status. It can break an independent rapper, but only in the context and company of the most major major-label artists, and this means it can't break a lot of them. P54

You can fear this. If you're a new artist trying to figure out how to make a living in music, it seems like a dauntingly hermetic system. Chance the Rapper, and the occasional similar stories, almost make it worse: they suggest that there is a principled and independent path to stardom, but don't explain how it can be walked. But this isn't a new fear, really. 'Step 5. Get on RapCaviar.' is only a minor variation on the old 'Step 5. Get signed.: probably no easier, but also probably no harder. In fact, most paths to 'Get on RapCaviar' still go through 'Get signed'. P54/55

So yes, it's true that the big gates still have keepers, and their uniforms smell a lot like the old ones. The winding, unguarded course up an implicit and shifting semi-hierarchical ladder of playlists isn't a real path, yet, not something you can just carefully follow to eventually cross over the wall. But it suggests a course of movement and effort that might feel more like climbing than like waiting to be airlifted by giant eagles. One stranger putting you on a rap playlist that five more strangers follow may not turn out to be the start of anything bigger for either of you, but it couldn't before, and now it could. P57

And because most people's listening is around the average amount, what effectively ends up happening is that the most active streamers get to say what happens to the money from people who are paying for subscriptions but not really using them. P63

It also has straightforward incentives for labels and artists: more streaming is always better. The label/artist incentives in a user-centric subscription scheme are kind of weird and ugly: you don't care how much your fans listen to your music, but you do want them to not listen to other artists. P63

On the whole, if more-active listeners listen to more-popular artists, then the pro rata scheme will be regressive in the economic (and social) sense, compared to the user-centric one, taxing the less-popular artists to consolidate wealth in the most-popular. Whereas if more-active listeners tend to listen to less-popular artists, then the pro rata scheme will be progressive, redistributing money from more-popular artists to less-popular ones. Thus this very basic question can be answered quantitatively by computing the average number of monthly streams per Spotify listener, and then calculating the average monthly total plays per artist of the artists played by listeners with fewer streams than that vs the ones with more. A ratio greater than I.o shows that pro rata is regressive, a ratio less than I.o shows that it's progressive, and either way it does so without revealing any remotely-proprietary actual counts or averages. When I monitored it at Spotify, it hovered around 0.83. More-active-than-average listeners play artists who are, on average, 0.83x as popular as the artists played by less-active-than-average listeners. The averages vary considerably across countries, and a little bit over time, and thus the ratio varies minorly in both dimensions as well, but not in magnitude or direc-tion. Pro rata is progressive, and user-centric would be regressive. P64

Explaining an algorithm is comforting in only a very limited and technical sense. The thing that puts recommendations' at the bottom of the playlist isn't trying to reinforce the power structures of decades of country radio, which it doesn't know about, even in the loose and mostly wrong sense in which it can be said to know anything at all. It not only doesn't know the genders of the artists, it doesn't even know their genres. It doesn't know any categorical difference between the words 'Country Music' and the words
'Theremin Frittata. It just knows that when other people have written those letters at the top of their playlists, they have tended to put these tracks below them. You can't blame math for the biases and flaws of society.
What you can blame, though, is the people who operate the math. We take a flawed world, and we try to reflect it back upon itself, but you can't reflect anything without changing its course.
This 'Country Music' case was, in technical terms, a simple matter of applied popularity bias in a situation where applying popularity bias is basically the mission statement of the feature to begin with. Statistical correlations aren't value-statements, though, and nobody was saying that those 135 manly country songs were more important or more culturally relevant to Country Music than Carrie Underwood or Martina McBride or Sara Evans. P88

Popularity not only reinforces the status quo, it usually mostly reports on it. P90

The SEO wars to dominate search results for box-fan noise are brutal, boch despite and because there is basically no way to make better' box-fan noises. The first tentative skirmishes of this war focused on what you might be searching for: 'fan noise, ocean sounds, Waves. But this quickly expanded to wky you might be searching: "an noise for sleeping, ocean sounds for meditation, Waves for studying. And from there to other, more conjectural premises: resonant frequencies for goal-affirmation, quiet rain storms for soothing babies, subliminal reinforcement for learning Mandarin. P97

Streaming and playlists are also sometimes blamed for requiring constant engagement, or rewarding only the artists willing to maintain an onerous level of non-musical fan-fascinating activity like social-media feeds and endless remixes. What about the artists (and again, the implication tends to be that these are the serious artists) who need two or three years of solitude to reach deep enough inside of themselves to find their next album? But I think this question presumes that all communities have the same dynamics, and that every artist with a slowly thoughtful artistic process is competing for the same fans as artists with fast ma-chinery. How can Zola Jesus' lonely, searching voice cut into the incessant din of BTS Army marches, for one plaintive example?
But that's not actually a problem Zola has. Competing for BTS's tans probably does require making relentless TikToks, because TikTok is an integral part of how those listeners find music that they listen to later, and how they express their reactions to their listening. Zola isn't doing that. BTS fans aren't the audience she's trying to reach, and her fans don't find music through hashtags or meme aesthetics. What she needs is a community of fans of diffi-cult, atmospheric music in search of obscure emotional truths. Or, having found such a community, once, she needs a way to find it again each time she comes back from her solitude with a new record. p109/110

It is now very possible to have a streaming music experience that is mostly managed by algorithms. It's not yet necessary. You can still treat a streaming service as a way of manually collecting individual songs from an infinite store if you insist, and the current share of listening programmed by algorithms is less than you might guess, but it seems pretty clear that algorithms are going to be enthusiastically present in music, and almost all aspects of technological life, for the foreseeable future. It is reasonable to be afraid of this. Algorithms are just tools, but sometimes their makers hand them to you and sometimes we strap you to a spinning board and throw them at your head. 

The algorithms don't care, either way. Only humans care.
Fortunately, we usually care a lot. We've gotten pretty good, collectively, at algorithms, and they often work. They make errors, too, but so do humans.
The ways in which algorithms fail, however, are different from the ways in which we're used to failing ourselves. People fail spectacularly by trying difficult things, but also fail sporadically at things that should be easy. Algorithms fail systematically by never knowing whether they're good at something or not. Even the best algorithms fail if they cannot distinguish bad from good, and thus cannot avoid giving bad answers along with good ones. P134/135

The name for letting computers do millions of things at once without laborious supervision is Machine Learning.
Conventional pre-Machine-Learning computer programming is done by humans writing some code and then tweaking it until the results are good. This assumes that someone on the team can tell better results from worse ones. You can't write conventional music-recommendation programs without knowing a lot about music.
The core idea of Machine Learning is that instead of telling the computer what to do, you tell it what the variables are, and how to judge the results, and you let some meta-algorithm find the combination of variables that produces the best results. Imagine a machine with a lot of levers. Instead of a human getting into the machine to operate the levers, they walk around to the front of the machine and explain the goals to it, and then the machine moves the levers itself. P138/139

Machine learning does for programming what microwave ovens did for cooking: they take a sensory craft based on feedback and adjustment, and replace it with a closed box that just beeps.
Saying you're a Machine Learning Engineer is like saying you're going to microwave anything you're given to cook. Microwaves in turn encourage frozen meals, and a whole ecosystem of non-cook-ing. We could microwave the cookies, too, come to think of it, allowing us to finally replace the last few troublesome work-slots in the company that used to require a domain-specific skill "baking", whatever that is).
By that point, the cookies probably suck. They don't have to, but they will have had a thousand chances to both get worse and be more profitable, and there are no cookie experts left to defend the original cookie principles. The engineers, however, won't mind.
They get to work on cutting-edge machine-learning algorithms instead of arguing with weird cooking-school graduates. They get to talk about cutting-edge ML algorithms instead of salt and gluten. Packing and pricing are just more variables for training the next model. Their stock-options are valuable, and their LinkedIn inboxes are full of ML recruiters from Google and Facebook.
And this is why, in turn, calling Google or Facebook or LinkedIn or TikTok 'evil' is unhelpful, not because there's no evil to consider, but because attributing media's socially damaging effects to direct malice is misunderstanding the essential nature of current media technology. People could have wrecked a cookie company by pursuing profits over chewiness, too, but it would have taken cynicism and time. ML can do it without malice, quickly. And unlike cookie baking or hole digging, virtually all current social, media or streaming experiences are driven by machine learning. What ML most enthusiastically facilitates is turning cultural problems into technical problems, reducing the need for qualitative human input, so that they can be addressed by engineers who don't have to know or care about the cultural details. Facebook didn't set out to promote disinformation, and TikTok wasn't specifically meant to primarily boost videos in which it looks like somebody attractive is about to take off their shirt. Instead, engineers set up processes that automatically and opaquely promoted more of whatever produced more time spent, and measured their success by time spent. But circularity is always dangerous, and time spent is a particularly weird metric. Sometimes people spend more time doing activities because those activities are engaging and rewarding.
But sometimes they keep doing them out of addiction, or inertia, or fear. Sometimes they persist for tangible but inconsequential rewards, or in pursuit of withheld gratification, or to justify the sunk cost of frustration, or in ignorance of their alternatives. The time, like the cookies, may suck. And we may have succeeded in building a self-fulfilling machine that teaches itself to suck harder.
This doesn't make machine learning bad, any more than it makes machines bad. But it means that those of us who employ ML algorithms have to accept responsibility for their cultural im-plications, and for the effects of their failures.
And this is where the two types of ML seem to me to materially diverge. My favorite ML failures in music are overwhelmingly of the first type, of training by example. We did a lot of this at the Echo Nest, using human training examples to drive ML processes for scoring songs on psychoacoustic properties like danceability and instrumentalness. Clearly the computers do not dance, and it wasn't our task to make them dance or understand dancing or maximize the time spent dancing. We told them some songs we thought were danceable, and some we thought weren't. Their goal was to find the combinations of measurable qualities that corresponded with these human judgments. P141/142/143

The old algorithm's set had been carefully filtered in many obsessive ways over the years as we learned which kinds of songs work well in algorithmically generated playlists and which don't. Songs with long silent gaps are bad, and we have software for detecting gaps. Commentary tracks detached from the songs they're explaining are bad, and we have software for distinguishing speaking from singing. Kids songs and Christmas songs are bad to mix with non-kids songs or non-Christmas songs, and we have things for those, too. Very long or very short songs are bad.
The new algorithm's set of eligible songs incorporated almost all of those same filters. But not the last one, so its pool of eligible songs was actually larger, and included both longer and shorter ones. It didn't care about the difference, because again, algorithms don't care, but it was trained that success is people playing more songs. If you give people shorter songs, they will play more of them in the same amount of time. This scores better, but isn't a better ex-perience. In fact, a lot of the short songs were objectively bad picks, and the new algorithm had optimized itself to play worse music.
Happily, once we realized this and re-ran the test with the same set of songs eligible for both algorithms, the new one scored about the same as the old one, which is what we expected to begin with.
We didn't get to brag about an improvement, but the engineers got to switch to the new system, and the playlists didn't get worse. The machines didn't learn anything, but we did. P147

Calling code learning, when it doesn't learn, encourages us, as the people both responsible and subject to algorithms, to think and behave as if it does learn. But failures in the applications of algorithms are always a critique of us. We trained them wrong, or we evaluated them wrong, or we optimized them for the wrong goal, or we meant well but we gave them power over us that we should have kept. We cannot, as programmers, program our way out of a lack of self-awareness, any more than as listeners we can consume our way out of being objectified. The algorithms will not adjudicate our human fights, automate our apologies, or optimize us into shared purpose. They will not save us, or save themselves. We have to be willing to say that the best bad answers are still bad, and take a human breath and ask the questions again until the answers are good. P148

We have a big advantage, in music, that the shopping site doesn't have for headphones or julienne blades, which is that people do a lot more listening than they do shopping. We can adjust the effects of our algorithms by changing our thresholds. If we include every listener who has ever heard a single Nightwish song, we get all the serious fans, but also all the people who only ever heard the one random Nightwish song that appeared on a 2018 video-game soundtrack, and the people who don't even usually listen to metal but heard the unrecognizable D] Orkidea trance remix of the instrumental version of Nightwish's 'Bye Bye Beautiful' on a Club Hits compilation. Conversely, if we only include people who have listened to every Nightwish album at least once all the way through, we get a much smaller set of people with a much more intently narrowed field of collective expertise. Too narrow, probably.
Many of those people listen to nothing but Nightwish, which is fine for Nightwish but not so good for knowledge.
In between these extremes, however, we have a lot of flexibility for how we balance coverage and specificity. The more you require a person to have listened to an artist to qualify as a fan, the fewer fans your threshold will produce, and thus the fewer artists will have enough fans for calculating overlap to be meaningful.
But we control that threshold, too, so we could say that only people who have played an artist 100 times in the last month qualify as superfans, but it only takes 10 superfans in common between two artists to make us suspect that they are similar. Or anybody who has played at least three different songs by the artist counts as a casual fan, but it takes 1000 casual fans in common between two artists to suggest similarity. We can do even better by considering that similarity is asym-metric. Nightwish have two million listeners. The Austrian symphonic metal band Visions of Atlantis, who formed in part due to Nightwish's inspiration, have 100,000 listeners. If 20,000 people listen to both bands, that means that 20% of Visions of Atlantis' listenership also listens to Nightwish, which is impressive. But only 1% of Nightwish listeners listen to Visions of Atlantis. P155/156

For Fans Also Like we calibrated the math so that the more popular an artist becomes, the more popular a list of Fans Also Like artists they earn. The talent show contestants get each other, and Rihanna and Ariana both get Miley Cyrus and Nicki Minaj. Nightwish (2m fans) get Epica (700k fans), Epica get the Dutch band Delain (300k). Visions of Atlantis (100k) get the Swiss band Lunatica (33k). If you wander through these connections you will tend to move gradually down the popularity scale, from the most general collective knowledge towards the more specific, which is a much more rewarding pattern for exploration than all clicks looping grimly back to the same few top stars. p156/157

There are never just three algorithms for anything, though.
Spotify's Discover Weekly is conceptually based on collective knowledge and similarity, but for historical reasons employs a completely different method from Fans Also Like. Instead of being based on overlap between artists' fans, Discover Weekly is based on co-occurrence of songs between listener-made playlists.
And instead of using simple math, like Fans Also Like, it uses a computer-science technique called vector embedding, which turns each thing (in this case a song) into a list of numbers. Vector embeddings are super useful for computing purposes, because they let you measure a distance between things by taking the square root of the sum of the squares of the differences between corresponding numbers in the lists for the two things. They're tricky, though, because the dimensions of a song are not clear or obvious in the way that, say, pain medications are measured by dosage and duration. Even a well-defined idea like tempo is a headache to reduce to a single number for a whole song if the song changes speeds. As human listeners, you and I might connect two particular songs because the singers have the same accent, or they both have a particular drum break, but the computers don't know that those elements affect us more than the overall arrangement or the amount of cowbell. Or two songs might be nearly identical in all but one of the dimensions we would think to describe them with, but that one dimension is the language of the lyrics, and thus one is a love song you feel like you could be inside of, and the other one reminds you of waiting for a missing rental car when you were meant to already be at the beach. P157/158

As a teenager in the 80s, I picked bands like choosing gods from a stipulated pantheon, or at best as if the radio let me select any god from any pantheon at all as long as the D'Aulaires wrote a book about it. As an internet kid, they basically pick peers (or nearly) who are just enough more famous than they are for the relationship to be practically asym-metric. Their favorites are thus naturally young, I think not mainly because they're juxtaposing grown-ups and kids and finding the adults intolerable, but because they recognize their imminent future selves so readily in the open sharing of people slightly ahead of them in either age or fame. P223